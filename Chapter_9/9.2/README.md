# Decision trees

We implement several decision trees on a one-vs-all decision problem with three classes of dummy data in 2D feature space (to allow for easy potting of the classes and decision boundaries). We use

* CART
* ID3
* Random Forests
* AdaBoost
* Gradient Boost
  
Run the comparison file with `python DT-comparison.py` or look at the Jupyter notebook [DT-comparison.ipynb](./DT-comparison.ipynb) to see the outputs directly.

